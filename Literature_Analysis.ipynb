{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Literature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation / Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read all the sheets in excel file(input) to a list of dataframes.\n",
    "2. Standardize the column names.\n",
    "3. Match the names in different sheets and update corresponding addresses.\n",
    " * Mark the conflicts in a different column.\n",
    "4. Merge London city and non-London city latitudes and longitudes.\n",
    "5. Update the latitudes and longitudes of entries with same addresses.\n",
    "6. Find the missing latitudes and longitudes for the addresses using API.\n",
    "7. Remove/merge unnecessary columns and create final dataframe.\n",
    "8. Write the final dataframe into excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim # Required to find latitudes and longitudes of places\n",
    "from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = 'data/Network Data Lists-7-14.xlsx'\n",
    "OUTPUT_FILE_NAME = 'data/Final_dataset.xlsx'\n",
    "INPUT_COLUMNS = ['Name', 'List_ID', 'Year', 'Reformatted_Name','Gender', 'is_from_London', 'London_Street',\n",
    "                 'London_Region', 'London_Lat_Long', 'City','Non_London_City_Lat_Long', 'Nation']\n",
    "INTERMEDIATE_COLUMNS = ['Name', 'List_ID', 'Year', 'Reformatted_Name','Gender', 'is_from_London', 'London_Street',\n",
    "                 'London_Region', 'London_Lat_Long', 'City','Non_London_City_Lat_Long', 'Nation', 'Conflits', 'location_update_from_other_sheet', 'coordinates']\n",
    "OUTPUT_COLUMNS = ['Name', 'Reformatted_Name', 'List_ID', 'Year','Gender', 'is_from_London', 'London_Street',\n",
    "                 'London_Region', 'City', 'Nation', 'Lat_Long', 'Conflits']\n",
    "SHEETS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read all the sheets in excel file(input) to a list of dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns list of dataframes\n",
    "def read_input():\n",
    "    global SHEETS\n",
    "    df_list = []\n",
    "    xl = pd.ExcelFile(INPUT_FILE_NAME)\n",
    "    SHEETS = xl.sheet_names[:-1]        # Remove last sheet(Project Details)\n",
    "    print(\"Sheets in dataframe\")\n",
    "    print(SHEETS)\n",
    "    for i in range(len(SHEETS)):\n",
    "        df = xl.parse(SHEETS[i])\n",
    "        df_list.append(df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standardize the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_column_names(df_list):\n",
    "    required_columns_df_list = []\n",
    "    extra_columns_df_list = []\n",
    "    for df in df_list:\n",
    "        df.columns = INPUT_COLUMNS + list(df.columns)[len(INPUT_COLUMNS):]\n",
    "        required_columns_df_list.append(df.loc[:,INPUT_COLUMNS])\n",
    "        extra_columns_df_list.append(df.loc[:,list(df.columns)[len(INPUT_COLUMNS):]])\n",
    "    # check_column_names(required_columns_df_list)\n",
    "    # check_column_names(extra_columns_df_list)\n",
    "    return required_columns_df_list, extra_columns_df_list\n",
    "\n",
    "# Utility function to check column names\n",
    "def check_column_names(df_list):\n",
    "    for df in df_list:\n",
    "        print(df.columns[:len(INPUT_COLUMNS)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Match the names in different sheets and update corresponding addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will add two new columns:\n",
    "# 1. 'location_update_from_other_sheet' : indicating whether the location entry was updated from other sheets\n",
    "# 2. 'Conflicts' : Indicates possible locations (Same name different addresses)\n",
    "\n",
    "def add_columns(df_list):\n",
    "    for df in df_list:\n",
    "        df['location_update_from_other_sheet'] = ''\n",
    "        df['Conflits'] = ''\n",
    "    return df_list\n",
    "\n",
    "def get_indexes_of_missing_address(df):\n",
    "    indexes = df[df['London_Street'].isnull() | df['London_Region'].isnull() | df['City'].isnull()].index.tolist()\n",
    "    return indexes\n",
    "\n",
    "def get_indexes_of_matching_names(df, name):\n",
    "    indexes = df[df['Reformatted_Name'] == name].index.tolist()\n",
    "    return indexes\n",
    "\n",
    "def update_row_col(df, row, col, val, matching_sheet_idx, matchin_row_idx):\n",
    "    if val != 'nan' and val != '0':\n",
    "        if str(df.loc[row, col]) == 'nan':\n",
    "                df.loc[row, col] = val\n",
    "                df.loc[row, 'location_update_from_other_sheet'] = 'Yes, Sheet:' + str(matching_sheet_idx) + ' row:' + str(matchin_row_idx)\n",
    "        elif df.loc[row, col] != val and df.loc[row, col]!=0:\n",
    "            df.loc[row, 'Conflits'] += ' '+col+' : '+val+ ' Sheet:' + str(matching_sheet_idx) + ' row:' + str(matchin_row_idx) + ','\n",
    "\n",
    "def update_address_crosscheck_df(df_list, df_idx):\n",
    "    missing_rows_indexes = get_indexes_of_missing_address(df_list[df_idx])\n",
    "    for missing_idx in missing_rows_indexes:  # Iterating over missing rows\n",
    "        for i in range(len(df_list)): # Iterating over other sheets(df)\n",
    "            if i != df_idx:           # Check for self sheet\n",
    "                matching_row_indexes = get_indexes_of_matching_names(df_list[i], df_list[df_idx].loc[missing_idx,'Reformatted_Name'])\n",
    "                for matching_idx in matching_row_indexes:\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'London_Street', str(df_list[i].loc[matching_idx, 'London_Street']), i, matching_idx)\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'London_Region', str(df_list[i].loc[matching_idx, 'London_Region']), i, matching_idx)\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'City', str(df_list[i].loc[matching_idx, 'City']), i, matching_idx)\n",
    "\n",
    "def update_address_crosscheck(df_list):\n",
    "    df_list = add_columns(df_list)\n",
    "    for i in range(len(df_list)):\n",
    "        update_address_crosscheck_df(df_list, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge London city and non-London city latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a new column 'coordinates' which has latitude and longitude of any address\n",
    "def merge_lat_long(df_list):\n",
    "    for df in df_list:\n",
    "        df['coordinates'] = np.nan\n",
    "        df.loc[df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0].index, 'coordinates'] = df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0]['London_Lat_Long']\n",
    "        df.loc[df[df['Non_London_City_Lat_Long'].notnull() & df['Non_London_City_Lat_Long']!=0].index, 'coordinates'] = df[df['Non_London_City_Lat_Long'].notnull() & df['Non_London_City_Lat_Long']!=0]['Non_London_City_Lat_Long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Update the latitudes and longitudes of entries with same addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "required_columns = ['London_Street', 'London_Region', 'City', 'Nation', 'coordinates']\n",
    "\n",
    "'''def get_unique_df(df_list):\n",
    "    unique_df = pd.DataFrame()\n",
    "    for df in df_list:\n",
    "        unique_df = unique_df.append(df[df['coordinates'].notnull()][required_columns].drop_duplicates(subset=required_columns[:-1]))\n",
    "    return unique_df\n",
    "\n",
    "def update_lat_lon_with_same_address(df_list):\n",
    "    unique_df = get_unique_df(df_list)\n",
    "    #print(unique_df.describe())\n",
    "    for df in df_list:\n",
    "        print('-------------')\n",
    "        print(sum(pd.merge(df, unique_df, on=required_columns[:-1], indicator=True))\n",
    "        #print(df[required_columns].loc[:,required_columns[:-1]].columns)\n",
    "        #print(unique_df.loc[:,required_columns[:-1]].columns)\n",
    "        #print(df[required_columns].loc[:,required_columns[:-1]]==unique_df.loc[:,required_columns[:-1]])'''\n",
    "\n",
    "def update_lat_lon_with_same_address(df_list):\n",
    "    large_df = pd.concat(dict(enumerate(df_list)), ignore_index=False)\n",
    "    for col in large_df:\n",
    "        large_df[col] = ['' if (not isinstance(val, str) and np.isnan(val)) else \n",
    "                   (val if isinstance(val, str) else str(int(val))) \n",
    "                   for val in large_df[col].tolist()]\n",
    "    large_df['coordinates'] = large_df.groupby(required_columns[:-1])['coordinates'].transform(lambda x: x.dropna().iloc[0] if x.notnull().any() else np.nan)\n",
    "    tmp_list = [x.reset_index(level=0, drop=True) for i, x in large_df.groupby(level=0)]\n",
    "    return tmp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Find the missing latitudes and longitudes for the addresses using API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geolocator = Nominatim()\n",
    "def get_location(street, region, city, nation):\n",
    "    try:\n",
    "        location = geolocator.geocode(street+' '+region+' '+ city+' '+nation, timeout=5)\n",
    "        if location == None:\n",
    "            location = geolocator.geocode(street+' '+city+' '+nation, timeout=5)\n",
    "            if location == None:\n",
    "                location = geolocator.geocode(region+' '+city+' '+nation, timeout=5)\n",
    "                if location == None:\n",
    "                    location = geolocator.geocode(city+' '+nation, timeout=5)\n",
    "                    if location == None:\n",
    "                        location = geolocator.geocode(nation, timeout=5)\n",
    "        return location\n",
    "    except Exception:\n",
    "        print(street, region, city, nation)\n",
    "        print(Exception.args)\n",
    "        return None\n",
    "\n",
    "def make_key(row):\n",
    "    return str(row['London_Street']) + str(row['London_Region']) + str(row['City']) + str(row['Nation'])\n",
    "\n",
    "def update_missing_coordinates_with_geoapi(df_list):\n",
    "    LOCATION_COLUMNS = ['London_Street', 'London_Region', 'City', 'Nation']\n",
    "    i = 0\n",
    "    for df in df_list:\n",
    "        new_df = df[df['coordinates']==''].loc[:,LOCATION_COLUMNS].dropna(axis=0, how='all', subset=LOCATION_COLUMNS)\n",
    "        print('Processing: ', SHEETS[i])\n",
    "        i += 1\n",
    "        for idx in new_df.index:\n",
    "            if df.loc[idx,'coordinates'] == '':\n",
    "                street = ''\n",
    "                region = ''\n",
    "                city = ''\n",
    "                nation = ''\n",
    "                if not pd.isnull(new_df.loc[idx,'London_Street']) and new_df.loc[idx,'London_Street']!='0':\n",
    "                    street = new_df.loc[idx,'London_Street']\n",
    "                if not pd.isnull(new_df.loc[idx,'London_Region']) and new_df.loc[idx,'London_Region']!='0':\n",
    "                    region = new_df.loc[idx,'London_Region']\n",
    "                if not pd.isnull(new_df.loc[idx,'City']) and new_df.loc[idx,'City']!=\"0\":\n",
    "                    city = new_df.loc[idx,'City']\n",
    "                if not pd.isnull(new_df.loc[idx,'Nation']) and new_df.loc[idx,'Nation']!='0':\n",
    "                    nation = new_df.loc[idx,'Nation']\n",
    "                location = get_location(street, region, city, nation)\n",
    "                #location = str(street) + str(region) + str(city) + str(nation)\n",
    "                \n",
    "                if location != None:\n",
    "                    #df.loc[df[df.apply(make_key,axis=1)==make_key(df.iloc[idx])].index.tolist(), 'coordinates'] = str(location)\n",
    "                    df.loc[df[df.apply(make_key,axis=1)==make_key(df.iloc[idx])].index.tolist(), 'coordinates'] = str(location.latitude) + \", \" + str(location.longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Remove/merge unnecessary columns and create final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_final_dataframe(df_list, extra_columns_df_list):\n",
    "    new_df = []\n",
    "    for i in range(len(df_list)):\n",
    "        new_df.append(pd.concat([df_list[i],extra_columns_df_list[i]], axis=1))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write the final dataframe into excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_xls(df_list):\n",
    "    global SHEETS\n",
    "    writer = ExcelWriter(OUTPUT_FILE_NAME)\n",
    "    for i in range(len(SHEETS)):\n",
    "        df_list[i].to_excel(writer,SHEETS[i])\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheets in dataframe\n",
      "['Emma Lyon 1812', 'Bolaffey 1820', 'Polack 1830', ' Moss 1839', ' Infant 1841', ' VOJ 1842-45', 'Belisario 1856']\n"
     ]
    }
   ],
   "source": [
    "df_list = read_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_list, extra_columns_df_list = standardize_column_names(df_list)\n",
    "#check_column_names(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_address_crosscheck(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_lat_long(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = update_lat_lon_with_same_address(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "update_missing_coordinates_with_geoapi(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_list = create_final_dataframe(df_list, extra_columns_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_xls(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
