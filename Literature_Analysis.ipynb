{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Literature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation / Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read all the sheets in excel file(input) to a list of dataframes.\n",
    "2. Standardize the column names.\n",
    "3. Match the names in different sheets and update corresponding addresses.\n",
    " * Mark the conflicts in a different column.\n",
    "4. Merge London city and non-London city latitudes and longitudes.\n",
    "5. Update the latitudes and longitudes of entries with same addresses.\n",
    "6. Find the missing latitudes and longitudes for the addresses using API.\n",
    "7. Remove/merge unnecessary columns and create final dataframe.\n",
    "8. Write the final dataframe into excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim # Required to find latitudes and longitudes of places\n",
    "from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = 'data/Network Data Lists-7-14.xlsx'\n",
    "OUTPUT_FILE_NAME = 'data/Final_dataset.xlsx'\n",
    "INPUT_COLUMNS = ['Name', 'List_ID', 'Year', 'Reformatted_Name','Gender', 'is_from_London', 'London_Street',\n",
    "                 'London_Region', 'London_Lat_Long', 'City','Non_London_City_Lat_Long', 'Nation']\n",
    "OUTPUT_COLUMNS = ['Name', 'Reformatted_Name', 'List_ID', 'Year','Gender', 'is_from_London', 'London_Street',\n",
    "                 'London_Region', 'City', 'Nation', 'Lat_Long', 'Conflits']\n",
    "SHEETS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read all the sheets in excel file(input) to a list of dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns list of dataframes\n",
    "def read_input():\n",
    "    global SHEETS\n",
    "    df_list = []\n",
    "    xl = pd.ExcelFile(INPUT_FILE_NAME)\n",
    "    SHEETS = xl.sheet_names[:-1]        # Remove last sheet(Project Details)\n",
    "    print(\"Sheets in dataframe\")\n",
    "    print(SHEETS)\n",
    "    for i in range(len(SHEETS)):\n",
    "        df = xl.parse(SHEETS[i])\n",
    "        df_list.append(df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standardize the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_column_names(df_list):\n",
    "    for df in df_list:\n",
    "        df.columns = INPUT_COLUMNS + list(df.columns)[len(INPUT_COLUMNS):]\n",
    "    return df_list\n",
    "\n",
    "# Utility function to check column names\n",
    "def check_column_names(df_list):\n",
    "    for df in df_list:\n",
    "        print(df.columns[:len(INPUT_COLUMNS)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Match the names in different sheets and update corresponding addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will add two new columns:\n",
    "# 1. 'location_update_from_other_sheet' : indicating whether the location entry was updated from other sheets\n",
    "# 2. 'Conflicts' : Indicates possible locations (Same name different addresses)\n",
    "\n",
    "def add_columns(df_list):\n",
    "    for df in df_list:\n",
    "        df['location_update_from_other_sheet'] = ''\n",
    "        df['Conflits'] = ''\n",
    "    return df_list\n",
    "\n",
    "def get_indexes_of_missing_address(df):\n",
    "    indexes = df[df['London_Street'].isnull() | df['London_Region'].isnull() | df['City'].isnull()].index.tolist()\n",
    "    return indexes\n",
    "\n",
    "def get_indexes_of_matching_names(df, name):\n",
    "    indexes = df[df['Reformatted_Name'] == name].index.tolist()\n",
    "    return indexes\n",
    "\n",
    "def update_row_col(df, row, col, val, matching_sheet_idx, matchin_row_idx):\n",
    "    if val != 'nan' and val != '0':\n",
    "        if str(df.loc[row, col]) == 'nan':\n",
    "                df.loc[row, col] = val\n",
    "                df.loc[row, 'location_update_from_other_sheet'] = 'Yes, Sheet:' + str(matching_sheet_idx) + ' row:' + str(matchin_row_idx)\n",
    "        elif df.loc[row, col] != val and df.loc[row, col]!=0:\n",
    "            df.loc[row, 'Conflits'] += ' '+col+' : '+val+ ' Sheet:' + str(matching_sheet_idx) + ' row:' + str(matchin_row_idx) + ','\n",
    "\n",
    "def update_address_crosscheck_df(df_list, df_idx):\n",
    "    missing_rows_indexes = get_indexes_of_missing_address(df_list[df_idx])\n",
    "    for missing_idx in missing_rows_indexes:  # Iterating over missing rows\n",
    "        for i in range(len(df_list)): # Iterating over other sheets(df)\n",
    "            if i != df_idx:           # Check for self sheet\n",
    "                matching_row_indexes = get_indexes_of_matching_names(df_list[i], df_list[df_idx].loc[missing_idx,'Reformatted_Name'])\n",
    "                for matching_idx in matching_row_indexes:\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'London_Street', str(df_list[i].loc[matching_idx, 'London_Street']), i, matching_idx)\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'London_Region', str(df_list[i].loc[matching_idx, 'London_Region']), i, matching_idx)\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'City', str(df_list[i].loc[matching_idx, 'City']), i, matching_idx)\n",
    "\n",
    "def update_address_crosscheck(df_list):\n",
    "    df_list = add_columns(df_list)\n",
    "    for i in range(len(df_list)):\n",
    "        update_address_crosscheck_df(df_list, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge London city and non-London city latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a new column 'coordinates' which has latitude and longitude of any address\n",
    "def merge_lat_long(df_list):\n",
    "    for df in df_list:\n",
    "        df['coordinates'] = np.nan\n",
    "        #print(df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0]['London_Lat_Long'])\n",
    "        print(df.loc[df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0].index, 'coordinates'])\n",
    "        df.loc[df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0].index, 'coordinates'] = df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0]['London_Lat_Long']\n",
    "        #df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0].loc['coordinates'] = df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0]['London_Lat_Long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Update the latitudes and longitudes of entries with same addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unique_df(df_list):\n",
    "    unique_df = df_list[0].dropna(subset=[])\n",
    "    \n",
    "\n",
    "def update_lat_lon_with_same_address(df_list):\n",
    "    unique_df = get_unique_df(df_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Find the missing latitudes and longitudes for the addresses using API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Remove/merge unnecessary columns and create final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write the final dataframe into excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_xls(df_list):\n",
    "    global SHEETS\n",
    "    writer = ExcelWriter(OUTPUT_FILE_NAME)\n",
    "    for i in range(len(SHEETS)):\n",
    "        df_list[i].to_excel(writer,SHEETS[i])\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheets in dataframe\n",
      "['Emma Lyon 1812', 'Bolaffey 1820', 'Polack 1830', ' Moss 1839', ' Infant 1841', ' VOJ 1842-45', 'Belisario 1856']\n"
     ]
    }
   ],
   "source": [
    "df_list = read_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_list = standardize_column_names(df_list)\n",
    "#check_column_names(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_address_crosscheck(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: coordinates, dtype: float64)\n",
      "51    NaN\n",
      "52    NaN\n",
      "53    NaN\n",
      "54    NaN\n",
      "55    NaN\n",
      "56    NaN\n",
      "57    NaN\n",
      "58    NaN\n",
      "59    NaN\n",
      "60    NaN\n",
      "67    NaN\n",
      "68    NaN\n",
      "75    NaN\n",
      "77    NaN\n",
      "82    NaN\n",
      "83    NaN\n",
      "84    NaN\n",
      "85    NaN\n",
      "90    NaN\n",
      "95    NaN\n",
      "96    NaN\n",
      "98    NaN\n",
      "99    NaN\n",
      "100   NaN\n",
      "102   NaN\n",
      "105   NaN\n",
      "106   NaN\n",
      "107   NaN\n",
      "108   NaN\n",
      "109   NaN\n",
      "       ..\n",
      "148   NaN\n",
      "149   NaN\n",
      "153   NaN\n",
      "154   NaN\n",
      "155   NaN\n",
      "164   NaN\n",
      "167   NaN\n",
      "168   NaN\n",
      "170   NaN\n",
      "172   NaN\n",
      "175   NaN\n",
      "176   NaN\n",
      "182   NaN\n",
      "184   NaN\n",
      "185   NaN\n",
      "186   NaN\n",
      "187   NaN\n",
      "189   NaN\n",
      "191   NaN\n",
      "192   NaN\n",
      "193   NaN\n",
      "196   NaN\n",
      "197   NaN\n",
      "198   NaN\n",
      "199   NaN\n",
      "200   NaN\n",
      "201   NaN\n",
      "202   NaN\n",
      "204   NaN\n",
      "205   NaN\n",
      "Name: coordinates, dtype: float64\n",
      "18    NaN\n",
      "23    NaN\n",
      "29    NaN\n",
      "32    NaN\n",
      "33    NaN\n",
      "34    NaN\n",
      "36    NaN\n",
      "40    NaN\n",
      "41    NaN\n",
      "42    NaN\n",
      "43    NaN\n",
      "44    NaN\n",
      "45    NaN\n",
      "48    NaN\n",
      "49    NaN\n",
      "50    NaN\n",
      "99    NaN\n",
      "100   NaN\n",
      "Name: coordinates, dtype: float64\n",
      "Series([], Name: coordinates, dtype: float64)\n",
      "236   NaN\n",
      "Name: coordinates, dtype: float64\n",
      "Series([], Name: coordinates, dtype: float64)\n",
      "74   NaN\n",
      "76   NaN\n",
      "Name: coordinates, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "merge_lat_long(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_xls(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
