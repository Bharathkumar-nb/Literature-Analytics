{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Literature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation / Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read all the sheets in excel file(input) to a list of dataframes.\n",
    "2. Standardize the column names.\n",
    "3. Match the names in different sheets and update corresponding addresses.\n",
    " * Mark the conflicts in a different column.\n",
    "4. Merge London city and non-London city latitudes and longitudes.\n",
    "5. Update the latitudes and longitudes of entries with same addresses.\n",
    "6. Find the missing latitudes and longitudes for the addresses using API.\n",
    "7. Remove/merge unnecessary columns and create final dataframe.\n",
    "8. Write the final dataframe into excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim # Required to find latitudes and longitudes of places\n",
    "from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_FILE_NAME = 'data/Network Data Lists-7-14.xlsx'\n",
    "OUTPUT_FILE_NAME = 'data/Final_dataset.xlsx'\n",
    "INPUT_COLUMNS = ['Name', 'List_ID', 'Year', 'Reformatted_Name','Gender', 'is_from_London', 'London_Street',\n",
    "                 'London_Region', 'London_Lat_Long', 'City','Non_London_City_Lat_Long', 'Nation']\n",
    "OUTPUT_COLUMNS = ['Name', 'Reformatted_Name', 'List_ID', 'Year','Gender', 'is_from_London', 'London_Street',\n",
    "                 'London_Region', 'City', 'Nation', 'Lat_Long', 'Conflits']\n",
    "SHEETS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read all the sheets in excel file(input) to a list of dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns list of dataframes\n",
    "def read_input():\n",
    "    global SHEETS\n",
    "    df_list = []\n",
    "    xl = pd.ExcelFile(INPUT_FILE_NAME)\n",
    "    SHEETS = xl.sheet_names[:-1]        # Remove last sheet(Project Details)\n",
    "    print(\"Sheets in dataframe\")\n",
    "    print(SHEETS)\n",
    "    for i in range(len(SHEETS)):\n",
    "        df = xl.parse(SHEETS[i])\n",
    "        df_list.append(df)\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standardize the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize_column_names(df_list):\n",
    "    for df in df_list:\n",
    "        df.columns = INPUT_COLUMNS + list(df.columns)[len(INPUT_COLUMNS):]\n",
    "    return df_list\n",
    "\n",
    "# Utility function to check column names\n",
    "def check_column_names(df_list):\n",
    "    for df in df_list:\n",
    "        print(df.columns[:len(INPUT_COLUMNS)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Match the names in different sheets and update corresponding addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will add two new columns:\n",
    "# 1. 'location_update_from_other_sheet' : indicating whether the location entry was updated from other sheets\n",
    "# 2. 'Conflicts' : Indicates possible locations (Same name different addresses)\n",
    "\n",
    "def add_columns(df_list):\n",
    "    for df in df_list:\n",
    "        df['location_update_from_other_sheet'] = ''\n",
    "        df['Conflits'] = ''\n",
    "    return df_list\n",
    "\n",
    "def get_indexes_of_missing_address(df):\n",
    "    indexes = df[df['London_Street'].isnull() | df['London_Region'].isnull() | df['City'].isnull()].index.tolist()\n",
    "    return indexes\n",
    "\n",
    "def get_indexes_of_matching_names(df, name):\n",
    "    indexes = df[df['Reformatted_Name'] == name].index.tolist()\n",
    "    return indexes\n",
    "\n",
    "def update_row_col(df, row, col, val, matching_sheet_idx, matchin_row_idx):\n",
    "    if val != 'nan' and val != '0':\n",
    "        if str(df.loc[row, col]) == 'nan':\n",
    "                df.loc[row, col] = val\n",
    "                df.loc[row, 'location_update_from_other_sheet'] = 'Yes, Sheet:' + str(matching_sheet_idx) + ' row:' + str(matchin_row_idx)\n",
    "        elif df.loc[row, col] != val and df.loc[row, col]!=0:\n",
    "            df.loc[row, 'Conflits'] += ' '+col+' : '+val+ ' Sheet:' + str(matching_sheet_idx) + ' row:' + str(matchin_row_idx) + ','\n",
    "\n",
    "def update_address_crosscheck_df(df_list, df_idx):\n",
    "    missing_rows_indexes = get_indexes_of_missing_address(df_list[df_idx])\n",
    "    for missing_idx in missing_rows_indexes:  # Iterating over missing rows\n",
    "        for i in range(len(df_list)): # Iterating over other sheets(df)\n",
    "            if i != df_idx:           # Check for self sheet\n",
    "                matching_row_indexes = get_indexes_of_matching_names(df_list[i], df_list[df_idx].loc[missing_idx,'Reformatted_Name'])\n",
    "                for matching_idx in matching_row_indexes:\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'London_Street', str(df_list[i].loc[matching_idx, 'London_Street']), i, matching_idx)\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'London_Region', str(df_list[i].loc[matching_idx, 'London_Region']), i, matching_idx)\n",
    "                    update_row_col(df_list[df_idx], missing_idx, 'City', str(df_list[i].loc[matching_idx, 'City']), i, matching_idx)\n",
    "\n",
    "def update_address_crosscheck(df_list):\n",
    "    df_list = add_columns(df_list)\n",
    "    for i in range(len(df_list)):\n",
    "        update_address_crosscheck_df(df_list, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge London city and non-London city latitudes and longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a new column 'coordinates' which has latitude and longitude of any address\n",
    "def merge_lat_long(df_list):\n",
    "    for df in df_list:\n",
    "        df['coordinates'] = np.nan\n",
    "        df.loc[df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0].index, 'coordinates'] = df[df['London_Lat_Long'].notnull() & df['London_Lat_Long']!=0]['London_Lat_Long']\n",
    "        df.loc[df[df['Non_London_City_Lat_Long'].notnull() & df['Non_London_City_Lat_Long']!=0].index, 'coordinates'] = df[df['Non_London_City_Lat_Long'].notnull() & df['Non_London_City_Lat_Long']!=0]['Non_London_City_Lat_Long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Update the latitudes and longitudes of entries with same addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "required_columns = ['London_Street', 'London_Region', 'City', 'Nation', 'coordinates']\n",
    "\n",
    "def get_unique_df(df_list):\n",
    "    unique_df = pd.DataFrame()\n",
    "    for df in df_list:\n",
    "        unique_df = unique_df.append(df[df['coordinates'].notnull()][required_columns].drop_duplicates(subset=required_columns[:-1]))\n",
    "    return unique_df\n",
    "\n",
    "def update_lat_lon_with_same_address(df_list):\n",
    "    unique_df = get_unique_df(df_list)\n",
    "    #print(unique_df.describe())\n",
    "    for df in df_list:\n",
    "        print('-------------')\n",
    "        print(sum(pd.merge(df, unique_df, on=required_columns[:-1], indicator=True))\n",
    "        #print(df[required_columns].loc[:,required_columns[:-1]].columns)\n",
    "        #print(unique_df.loc[:,required_columns[:-1]].columns)\n",
    "        #print(df[required_columns].loc[:,required_columns[:-1]]==unique_df.loc[:,required_columns[:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Find the missing latitudes and longitudes for the addresses using API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Remove/merge unnecessary columns and create final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write the final dataframe into excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_xls(df_list):\n",
    "    global SHEETS\n",
    "    writer = ExcelWriter(OUTPUT_FILE_NAME)\n",
    "    for i in range(len(SHEETS)):\n",
    "        df_list[i].to_excel(writer,SHEETS[i])\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheets in dataframe\n",
      "['Emma Lyon 1812', 'Bolaffey 1820', 'Polack 1830', ' Moss 1839', ' Infant 1841', ' VOJ 1842-45', 'Belisario 1856']\n"
     ]
    }
   ],
   "source": [
    "df_list = read_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_list = standardize_column_names(df_list)\n",
    "#check_column_names(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update_address_crosscheck(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lat_long(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "0\n",
      "-------------\n",
      "0\n",
      "-------------\n",
      "0\n",
      "-------------\n",
      "0\n",
      "-------------\n",
      "0\n",
      "-------------\n",
      "0\n",
      "-------------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "update_lat_lon_with_same_address(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_xls(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
